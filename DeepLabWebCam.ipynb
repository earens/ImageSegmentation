{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DeepLabv3+ Pretrained on Pascal Voc and applied on WebCam data**\n",
    "\n",
    "This code applies the pretrained DeepLabv3+ on web cam data. The model is trained on Pascal Voc and therefore outputs the segmentations based on the Pascal Voc classes. \n",
    "\n",
    "https://www.novatec-gmbh.de/blog/semantic-segmentation-part-1-deeplab-v3/\n",
    "\n",
    "In order to run the code you have to clone the following repository first which contains the model functions:\n",
    "https://github.com/tensorflow/models/tree/master/research/deeplab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import collections\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import tarfile\n",
    "import tempfile\n",
    "import urllib\n",
    "from IPython import display\n",
    "from ipywidgets import interact\n",
    "from ipywidgets import interactive\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "sys.path.append('utils')\n",
    "import get_dataset_colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model with xception backbone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3157318cbb084472b9e06831635cfda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=('xception_coco_voctrainaug', 'xception_coco_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading model to /var/folders/mh/3mvsvbk16px4jc19dn1pmdt40000gn/T/tmpzauw7d71/deeplab_model.tar.gz, this might take a while...\n",
      "download completed!\n"
     ]
    }
   ],
   "source": [
    "#Download URLs of the pre-trained Xception model\n",
    "_MODEL_URLS = {\n",
    "    'xception_coco_voctrainaug': 'http://download.tensorflow.org/models/deeplabv3_pascal_train_aug_2018_01_04.tar.gz',\n",
    "    'xception_coco_voctrainval': 'http://download.tensorflow.org/models/deeplabv3_pascal_trainval_2018_01_04.tar.gz',\n",
    "}\n",
    "\n",
    "Config = collections.namedtuple('Config', 'model_url, model_dir')\n",
    "\n",
    "def get_config(model_name, model_dir):\n",
    "    return Config(_MODEL_URLS[model_name], model_dir)\n",
    "\n",
    "config_widget = interactive(get_config, model_name=_MODEL_URLS.keys(), model_dir='')\n",
    "display.display(config_widget)\n",
    "\n",
    "_TARBALL_NAME = 'deeplab_model.tar.gz'\n",
    "\n",
    "config = config_widget.result\n",
    "\n",
    "#create directory\n",
    "model_dir = config.model_dir or tempfile.mkdtemp()\n",
    "tf.gfile.MakeDirs(model_dir)\n",
    "\n",
    "download_path = os.path.join(model_dir, _TARBALL_NAME)\n",
    "print('downloading model to %s, this might take a while...' % download_path)\n",
    "urllib.request.urlretrieve(config.model_url, download_path)\n",
    "print('download completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to load DeepLab model and run inference.\n",
    "class DeepLab(object):\n",
    "    INPUT_TENSOR = 'ImageTensor:0'\n",
    "    OUTPUT_TENSOR = 'SemanticPredictions:0'\n",
    "    INPUT_SIZE = 513\n",
    "    # Creates and loads pretrained Deeplab model\n",
    "    def __init__(self, tarball_path):\n",
    "        self.graph = tf.Graph()\n",
    "        graph_def = None\n",
    "        tar_file = tarfile.open(tarball_path)\n",
    "        for tar_info in tar_file.getmembers():\n",
    "            if _FROZEN_GRAPH in os.path.basename(tar_info.name):\n",
    "                file_handle = tar_file.extractfile(tar_info)\n",
    "                graph_def = tf.GraphDef.FromString(file_handle.read())\n",
    "                break\n",
    "        tar_file.close()\n",
    "        if graph_def is None:\n",
    "            raise RuntimeError('Cant find graph.')\n",
    "\n",
    "        with self.graph.as_default():      \n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "        \n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "     # Run inference on a single image\n",
    "    def run(self, image):\n",
    "        # Args: PIL.image object\n",
    "        width, height = image.size\n",
    "        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "        target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "        resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
    "        batch_seg_map = self.sess.run(\n",
    "            self.OUTPUT_TENSOR,\n",
    "            feed_dict={self.INPUT_TENSOR: [np.asarray(resized_image)]})\n",
    "        seg_map = batch_seg_map[0]\n",
    "        # Output: RGB image resized from original input image, segmentation map of resized image \n",
    "        return resized_image, seg_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get camera input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FROZEN_GRAPH = 'frozen_inference_graph'\n",
    "#Every time you run the code, a new model will be downloaded. Change the following line to a local path!\n",
    "model = DeepLab(download_path)\n",
    "cap = cv2.VideoCapture(0)\n",
    "final = np.zeros((1, 384, 1026, 3))\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2_im = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_im = Image.fromarray(cv2_im)\n",
    "    # model\n",
    "    resized_im, seg_map = model.run(pil_im)\n",
    "    # color of mask\n",
    "    seg_image = get_dataset_colormap.label_to_color_image(\n",
    "        seg_map, get_dataset_colormap.get_pascal_name()).astype(np.uint8)\n",
    "    \n",
    "    frame = np.array(pil_im)\n",
    "    r = seg_image.shape[1] / frame.shape[1]\n",
    "    dim = (int(frame.shape[0] * r), seg_image.shape[1])[::-1]\n",
    "    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "    resized = cv2.cvtColor(resized, cv2.COLOR_RGB2BGR)\n",
    "    color_and_mask = np.hstack((resized, seg_image))\n",
    "    cv2.imshow('frame', color_and_mask)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
